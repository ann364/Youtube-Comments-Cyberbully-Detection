{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> Data Scraping </center></h1>\n",
    "\n",
    "<img src=https://miro.medium.com/max/1190/1*2dK2BfTULH9Sjk30A61Siw.jpeg style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import google.oauth2.credentials\n",
    " \n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The CLIENT_SECRETS_FILE stores filename that contains OAuth 2.0 information for youtube app with client_id and client_secret.\n",
    "\n",
    "CLIENT_SECRETS_FILE = \"client_secret.json\"\n",
    "\n",
    "# OAuth 2.0 allows for read/write access to the authenticated user's account and requires requests to use an SSL connection.\n",
    "SCOPES = ['https://www.googleapis.com/auth/youtube.force-ssl']\n",
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "\n",
    "DEVELOPER_KEY= \"\"\n",
    "\n",
    "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION,developerKey=DEVELOPER_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION 1: \n",
    "# Performs youtube search query. Stores  urls in a file\n",
    "# Returns videoIds of Urls as a list\n",
    "\n",
    "def get_videolinks_youtube_search(textToSearch,filename):\n",
    "    query = urllib.parse.quote(textToSearch)\n",
    "    url = \"https://www.youtube.com/results?search_query=\" + query\n",
    "    response = urllib.request.urlopen(url)\n",
    "    html = response.read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    videoIds=[]\n",
    "    f = open(filename+\".csv\", \"w\")\n",
    "    for vid in soup.findAll(attrs={'class':'yt-uix-tile-link'}):\n",
    "        video_id = vid['href'].replace('/watch?v=','').partition('&')[0]\n",
    "        actual_url = 'https://youtu.be/' + video_id\n",
    "        videoIds.append((video_id))\n",
    "        f.write(actual_url+'\\n')\n",
    "    print(videoIds)\n",
    "    f.close()\n",
    "    \n",
    "    return videoIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION 2:\n",
    "# Reads list of video urls from a file\n",
    "# Returns videoIds of the urls\n",
    "\n",
    "def get_videoIds(filename):\n",
    "    class Helper:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "        def id_from_url(self,url:str):\n",
    "            return url.rsplit(\"/\",1)[1] \n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        content = f.readlines()\n",
    "\n",
    "    content = list(map(lambda s: s.strip(), content))\n",
    "    content = list(map(lambda s: s.strip(','), content))\n",
    "\n",
    "    helper = Helper()\n",
    "    videoIds = []\n",
    "    for youtube_url in content:\n",
    "        video_id = helper.id_from_url(youtube_url)\n",
    "        videoIds.append(str(video_id))\n",
    "        \n",
    "    return videoIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION 3:\n",
    "# Returns general description of each videos\n",
    "\n",
    "def get_video_info(videoIds):\n",
    "    videoInfoJson = youtube.videos().list(id=videoIds, part='snippet').execute()\n",
    "    return videoInfoJson\n",
    "\n",
    "\n",
    "# FUNCTION 4:\n",
    "# Returns statistics of each videos\n",
    "\n",
    "def get_video_stat(videoId):\n",
    "    videoStatisticsJson = youtube.videos().list(part='statistics, snippet', id=videoId).execute() \n",
    "    return videoStatisticsJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION 5:\n",
    "# Returns comment json of each videos\n",
    "\n",
    "def get_comments(video_id):\n",
    "    comments_json = youtube.commentThreads().list(\n",
    "        part = \"snippet\",\n",
    "        videoId = video_id,\n",
    "        textFormat = \"plainText\",\n",
    "        maxResults = 100\n",
    "    ).execute()\n",
    "    return comments_json\n",
    "\n",
    "# FUNCTION 6:\n",
    "# Returns reply json of each comment\n",
    "\n",
    "def get_replies(comment_id):\n",
    "    replies_json = youtube.comments().list(\n",
    "        part = \"snippet\",\n",
    "        parentId = comment_id,\n",
    "        textFormat = \"plainText\",\n",
    "    ).execute()\n",
    "    return replies_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION 7:\n",
    "# Reads comment json (100 items) \n",
    "# Returns information of comments n replies \n",
    "\n",
    "def get_comment_reply_info(commentsJson):\n",
    "# \tcommentsJson = get_comments(videoId)\n",
    "\trowList=[]\n",
    "\tfor item in commentsJson[\"items\"]:\n",
    "\t\tcommentorChannelId = item['snippet']['topLevelComment']['snippet']['authorChannelId']['value']\n",
    "\t\tcommentor = item['snippet']['topLevelComment']['snippet']['authorDisplayName']\n",
    "\t\tcommentText = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "\t\tcommentLikes = item['snippet']['topLevelComment']['snippet']['likeCount']\n",
    "\n",
    "\t\treply_count = item['snippet']['totalReplyCount']\n",
    "\t\tcomment_id = item['snippet']['topLevelComment']['id']\n",
    "\n",
    "\t\trow=[commentorChannelId,commentor,commentText,commentLikes]\n",
    "\t\trowList.append(row)\n",
    "\n",
    "\t\tif (reply_count>0): #Getting replies \n",
    "\t\t\trepliesJson = get_replies(comment_id)\n",
    "\t\t\tfor item in repliesJson['items']:\n",
    "\t\t\t\treplierChannelId = item['snippet']['authorChannelId']['value']\n",
    "\t\t\t\treplier = item['snippet']['authorDisplayName']\n",
    "\t\t\t\treplyText = item['snippet']['textDisplay']\n",
    "\t\t\t\treplyLikes = item['snippet']['likeCount']\n",
    "\t\t\t\treply_row=[replierChannelId,replier,replyText,replyLikes]\n",
    "\t\t\t\trowList.append(reply_row)\n",
    "\tdf = pd.DataFrame(rowList)\n",
    "\tdf\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION 8:\n",
    "# Reads video Id \n",
    "# Returns all information of comments n replies in dataframe format \n",
    "\n",
    "def get_comment_reply_info_from_all_pages(video_id):\n",
    "\tww = get_comments(video_id)\n",
    "    \n",
    "\t#Get first page comment reply info\n",
    "\tdf = get_comment_reply_info(ww)\n",
    "\tdf_all3 = pd.DataFrame()\n",
    "\tdf_all3 = df_all3.append(df, ignore_index=True, sort=False)\n",
    "    \n",
    "\t#Keep getting comments from the following pages\n",
    "\tpageCount=1\n",
    "\twhile ('nextPageToken' in ww) and (pageCount<=2): # Getting comments from three pages\n",
    "\t\tww = youtube.commentThreads().list(\n",
    "\t\tpart=\"snippet\",\n",
    "\t\tmaxResults=100, \n",
    "\t\tpageToken = ww['nextPageToken'],\n",
    "\t\tvideoId=video_id).execute()\n",
    "\t\tdf2  = get_comment_reply_info(ww)\n",
    "\t\tdf_all3 = df_all3.append(df2, ignore_index=True, sort=False)\n",
    "\t\tpageCount=pageCount+1\n",
    "        \n",
    "\theader = ['CommentorChannelId', 'Commentor', 'Comments', 'CommentLikes']\n",
    "\tdf_all3.columns = header\n",
    "\treturn df_all3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION 9:\n",
    "# Reads video Id \n",
    "# Returns all comments n replies in a single text format\n",
    "\n",
    "def get_comments_replies_as_string(video_id):\n",
    "    allCommentReplies =[]\n",
    "    df = get_comment_reply_info_from_all_pages(video_id)\n",
    "    for i in range(len(df['Comments'])):\n",
    "        allCommentReplies.append(df['Comments'][i])\n",
    "    return ' '.join(allCommentReplies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION 10:\n",
    "# Read videoIds\n",
    "# display video info, stats, comment as one string in dataframe\n",
    "\n",
    "def get_video_info_stats_comments(videoIds):\n",
    "    rowList=[]\n",
    "\n",
    "    #Getting basic video information \n",
    "    videoInfo=get_video_info(', '.join(videoIds))\n",
    "\n",
    "    for item in videoInfo['items']:\n",
    "        uploader = item['snippet']['channelTitle']\n",
    "        videoId = item['id']\n",
    "        title = item['snippet']['title']\n",
    "        description = item['snippet']['description']   \n",
    "\n",
    "        #Getting video statistics\n",
    "        videoStatistics = get_video_stat(videoId)\n",
    "        \n",
    "        viewCount = videoStatistics['items'][0]['statistics']['viewCount']\n",
    "        likeCount = videoStatistics['items'][0]['statistics']['likeCount']\n",
    "        dislikeCount = videoStatistics['items'][0]['statistics']['dislikeCount']\n",
    "        commentCount = videoStatistics['items'][0]['statistics']['commentCount']\n",
    "\n",
    "        #Getting all comments and replies from a video\n",
    "        commentText = get_comments_replies_as_string(videoId)\n",
    "\n",
    "        row = [uploader, videoId, title, description,viewCount, likeCount, dislikeCount, commentCount, commentText]\n",
    "        rowList.append(row)\n",
    "    \n",
    "    header = ['Uploader', 'VideoId', 'VideoTitle',\n",
    "              'Description','View Count', 'Likes',\n",
    "              'Dislikes', 'Comment Count','Comments']\n",
    "    df = pd.DataFrame(rowList, columns = header)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting Videos**\n",
    "\n",
    "Let us read URLs from our video collection and get videoIds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2mg3sFuiwRw Wlub9KOJBt4 D2iCOMoOkyI _Uxw2X0hNGg -9BfaW69LSk\n"
     ]
    }
   ],
   "source": [
    "# Getting videos\n",
    "link_file = \"ppl_bullied.csv\"\n",
    "videoIds = get_videoIds(link_file)\n",
    "\n",
    "print(*videoIds[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting Information of Videos**\n",
    "\n",
    "For this project I would like to have information of uploader or video subject, title and description of the video, count, likes, dislikes, total comments of the video. \n",
    "\n",
    "I would also like to have ~~all~~ three-page comments retrieved per video as a single text so later on I can analyze what kind of comment each uploader is getting. (I choose to have three-page comments since there is limit on api data retrieval from YouTube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uploader</th>\n",
       "      <th>VideoId</th>\n",
       "      <th>VideoTitle</th>\n",
       "      <th>Description</th>\n",
       "      <th>View Count</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Dislikes</th>\n",
       "      <th>Comment Count</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emily Ann Shaheen</td>\n",
       "      <td>2mg3sFuiwRw</td>\n",
       "      <td>HOW TO BE AN ARAB GIRL!</td>\n",
       "      <td>Heyyy guys! Thank you so much for watching! Th...</td>\n",
       "      <td>80408</td>\n",
       "      <td>1971</td>\n",
       "      <td>147</td>\n",
       "      <td>640</td>\n",
       "      <td>Im Arab from iraq but my golden name is in eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emily Ann Shaheen</td>\n",
       "      <td>Wlub9KOJBt4</td>\n",
       "      <td>ARAB GIRL STEREOTYPES!</td>\n",
       "      <td>Thanks for watching babes! xx, Emily Ann Shahe...</td>\n",
       "      <td>27925</td>\n",
       "      <td>608</td>\n",
       "      <td>46</td>\n",
       "      <td>240</td>\n",
       "      <td>Being an Arab is great and proud also true we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nowthisisliving</td>\n",
       "      <td>D2iCOMoOkyI</td>\n",
       "      <td>LESBIAN INTERVIEWS EX BOYFRIEND</td>\n",
       "      <td>please be kind in the comments, this boy is th...</td>\n",
       "      <td>2098024</td>\n",
       "      <td>51987</td>\n",
       "      <td>1644</td>\n",
       "      <td>2718</td>\n",
       "      <td>My ex broke up with me because she wanted to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nowthisisliving</td>\n",
       "      <td>_Uxw2X0hNGg</td>\n",
       "      <td>why we broke up</td>\n",
       "      <td>I know this is a tough video for everyone. We ...</td>\n",
       "      <td>3081184</td>\n",
       "      <td>74616</td>\n",
       "      <td>1766</td>\n",
       "      <td>9406</td>\n",
       "      <td>still high key want them to get back together ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Madison Beer</td>\n",
       "      <td>-9BfaW69LSk</td>\n",
       "      <td>Madison Beer- Catch Me Cover</td>\n",
       "      <td>HEY YOUTUBE!!!!!!!!! LONG TIME NO VIDEO! so so...</td>\n",
       "      <td>920561</td>\n",
       "      <td>14418</td>\n",
       "      <td>2408</td>\n",
       "      <td>2747</td>\n",
       "      <td>Be strong That's my fav song of demi lovato I'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Uploader      VideoId                       VideoTitle  \\\n",
       "0  Emily Ann Shaheen  2mg3sFuiwRw          HOW TO BE AN ARAB GIRL!   \n",
       "1  Emily Ann Shaheen  Wlub9KOJBt4           ARAB GIRL STEREOTYPES!   \n",
       "2    nowthisisliving  D2iCOMoOkyI  LESBIAN INTERVIEWS EX BOYFRIEND   \n",
       "3    nowthisisliving  _Uxw2X0hNGg                  why we broke up   \n",
       "4       Madison Beer  -9BfaW69LSk     Madison Beer- Catch Me Cover   \n",
       "\n",
       "                                         Description View Count  Likes  \\\n",
       "0  Heyyy guys! Thank you so much for watching! Th...      80408   1971   \n",
       "1  Thanks for watching babes! xx, Emily Ann Shahe...      27925    608   \n",
       "2  please be kind in the comments, this boy is th...    2098024  51987   \n",
       "3  I know this is a tough video for everyone. We ...    3081184  74616   \n",
       "4  HEY YOUTUBE!!!!!!!!! LONG TIME NO VIDEO! so so...     920561  14418   \n",
       "\n",
       "  Dislikes Comment Count                                           Comments  \n",
       "0      147           640  Im Arab from iraq but my golden name is in eng...  \n",
       "1       46           240  Being an Arab is great and proud also true we ...  \n",
       "2     1644          2718  My ex broke up with me because she wanted to b...  \n",
       "3     1766          9406  still high key want them to get back together ...  \n",
       "4     2408          2747  Be strong That's my fav song of demi lovato I'...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting video information\n",
    "vidInfo = get_video_info_stats_comments(videoIds)\n",
    "vidInfo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pickling the video Information and Comments\n",
    "vidInfo.to_pickle(\"videoInfo.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting Comment and Replies:**\n",
    "\n",
    "I would also like to analyze commenters and their comments in next iteration of this project. So, I would like to get comments and replies data like Commenter, comment likes, comment text etc.\n",
    "\n",
    "For each video, I would like to save the comment/reply data in a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting comment/reply video\n",
    "filepath = \"Comments\"\n",
    "\n",
    "for item in videoIds:\n",
    "    commentInfo=get_comment_reply_info_from_all_pages(item)\n",
    "    \n",
    "    ##pickle each of comment info from a video into its own indivdual file\n",
    "    filename = str(item)+\"_commentInfo.pkl\"\n",
    "    commentInfo.to_pickle(os.path.join(filepath, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CommentorChannelId</th>\n",
       "      <th>Commentor</th>\n",
       "      <th>Comments</th>\n",
       "      <th>CommentLikes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCXkTts-5OgoyUgY4sOuWZOg</td>\n",
       "      <td>Phoenix Masami</td>\n",
       "      <td>Liar I knew it hey no he said and I quote \"Go ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCjpS5M1bpmS6MnCkswYpZ7Q</td>\n",
       "      <td>who knows?</td>\n",
       "      <td>Too bad this rat tailed product of trailer tra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCsflmw50EadncHYtbpGY1xA</td>\n",
       "      <td>Samuelrey 1213</td>\n",
       "      <td>The worst thing you can do to someone:say some...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCseM3rY7y7Iv5ieaqZfTHjQ</td>\n",
       "      <td>RazorbladeRomance</td>\n",
       "      <td>\"He abused me first\" \\n\\nOh shut up...we all k...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UCK2JiKKdNrIkD7qituzCqsw</td>\n",
       "      <td>ツ IᑕᕼᗷIᑎᕮIᑎᕼᗩᑎS</td>\n",
       "      <td>He earned another bodyslam for lying</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CommentorChannelId          Commentor  \\\n",
       "0  UCXkTts-5OgoyUgY4sOuWZOg     Phoenix Masami   \n",
       "1  UCjpS5M1bpmS6MnCkswYpZ7Q         who knows?   \n",
       "2  UCsflmw50EadncHYtbpGY1xA     Samuelrey 1213   \n",
       "3  UCseM3rY7y7Iv5ieaqZfTHjQ  RazorbladeRomance   \n",
       "4  UCK2JiKKdNrIkD7qituzCqsw    ツ IᑕᕼᗷIᑎᕮIᑎᕼᗩᑎS   \n",
       "\n",
       "                                            Comments  CommentLikes  \n",
       "0  Liar I knew it hey no he said and I quote \"Go ...             0  \n",
       "1  Too bad this rat tailed product of trailer tra...             0  \n",
       "2  The worst thing you can do to someone:say some...             1  \n",
       "3  \"He abused me first\" \\n\\nOh shut up...we all k...             0  \n",
       "4               He earned another bodyslam for lying             0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking last video's comment information\n",
    "commentInfo.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
